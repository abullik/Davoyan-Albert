{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VerbGovernment:\n",
    "    \n",
    "    def __init__(self, verb, table):\n",
    "        self.verb = verb\n",
    "        self.table = table\n",
    "        self.examples = dict()\n",
    "        self.possible_preps = self.pmi_preps()\n",
    "        import pymorphy2\n",
    "        self.morph = pymorphy2.MorphAnalyzer()\n",
    "        \n",
    "    def isProperName(self, word):\n",
    "        bad_tags = ['Surn', 'Abbr', 'Name', 'Patr', 'Geox', 'Orgn', 'Trad']\n",
    "        tags = self.morph.parse(word)\n",
    "        for row in tags:\n",
    "            for bad_tag in bad_tags:\n",
    "                if {bad_tag} in row.tag:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    def pmi_nouns(self):\n",
    "        import math,statistics\n",
    "        from time import time\n",
    "        start = time()\n",
    "\n",
    "        nouns = dict()\n",
    "        for index, _ in self.table[self.table.lemma == self.verb].iterrows():\n",
    "            if self.table['gramm'].loc[index][2] not in 'mpgn':\n",
    "                words = 0\n",
    "                left = 1\n",
    "                while self.table['link'].loc[index - left] != 'PUNC' and words < 5:\n",
    "                    words += 1 \n",
    "                    current_word = self.table['lemma'].loc[index - left]\n",
    "                    if self.table['POS'].loc[index - left] == 'N' and not self.isProperName(current_word):\n",
    "                        nouns[current_word] = nouns.get(current_word, 0) + 1 \n",
    "                    left +=1\n",
    "\n",
    "                right = 1\n",
    "                words = 0\n",
    "                while self.table['link'].loc[index + right] != 'PUNC' and words < 5:\n",
    "                    words += 1\n",
    "                    current_word = self.table['lemma'].loc[index + right]\n",
    "                    if self.table['POS'].loc[index + right] == 'N' and not self.isProperName(current_word):\n",
    "                        nouns[current_word] = nouns.get(current_word, 0) + 1 \n",
    "                    right +=1\n",
    "        \n",
    "        nouns_pmi = dict()\n",
    "        words_number = len(self.table[(self.table['link'] != 'PUNC') & (self.table['head'] != 'PUNC')])\n",
    "        verb_freq = len(self.table[self.table.lemma == self.verb]) / words_number\n",
    "        margin = statistics.mean(nouns.values())\n",
    "\n",
    "        for noun in nouns.keys():\n",
    "            if nouns[noun] < margin:\n",
    "                continue\n",
    "            noun_freq = len(self.table[self.table.lemma == noun]) / words_number\n",
    "            together_freq = nouns[noun] / words_number\n",
    "            nouns_pmi[noun] = math.log(together_freq / (noun_freq * verb_freq))\n",
    "            \n",
    "        print('Calculation time: {}'.format((time() - start) / 60))\n",
    "        return sorted(nouns_pmi, key=nouns_pmi.get, reverse=True)[:5]\n",
    "        \n",
    "        \n",
    "    \n",
    "    def pmi_preps(self):\n",
    "        import math,statistics\n",
    "        \n",
    "        prepositions = dict()\n",
    "        for index, _ in self.table[self.table.lemma == self.verb].iterrows():\n",
    "            if self.table['gramm'].loc[index][2] not in 'mpgn':\n",
    "                words = 0\n",
    "                left = 1\n",
    "                while self.table['link'].loc[index - left] != 'PUNC' and words < 5 and index - left >= 0:\n",
    "                    words += 1 \n",
    "                    current_word = self.table['lemma'].loc[index - left]\n",
    "                    if self.table['POS'].loc[index - left] == 'S':\n",
    "                        prepositions[current_word] = prepositions.get(current_word, 0) + 1 \n",
    "                    left +=1\n",
    "\n",
    "                right = 1\n",
    "                words = 0\n",
    "                while self.table['link'].loc[index + right] != 'PUNC' and words < 5 and index + right < len(self.table):\n",
    "                    words += 1\n",
    "                    current_word = self.table['lemma'].loc[index + right]\n",
    "                    if self.table['POS'].loc[index + right] == 'S':\n",
    "                        prepositions[current_word] = prepositions.get(current_word, 0) + 1 \n",
    "                    right +=1\n",
    "\n",
    "        prep_pmi = dict()\n",
    "        words_number = len(self.table[(self.table['link'] != 'PUNC') & (self.table['head'] != 'PUNC')])\n",
    "        verb_freq = len(self.table[self.table.lemma == self.verb]) / words_number\n",
    "        margin = statistics.mean(prepositions.values())\n",
    "\n",
    "        for prep in prepositions.keys():\n",
    "            if prepositions[prep] < margin:\n",
    "                continue\n",
    "            prep_freq = len(self.table[self.table.lemma == prep]) / words_number\n",
    "            together_freq = prepositions[prep] / words_number\n",
    "\n",
    "            prep_pmi[prep] = math.log(together_freq / (prep_freq * verb_freq))\n",
    "\n",
    "        return sorted(prep_pmi, key=prep_pmi.get, reverse=True)[:5]\n",
    "\n",
    "    \n",
    "    def get_case(self, tag):\n",
    "        if tag[0] == 'S':\n",
    "            return tag[3]\n",
    "        elif tag[0] == 'N':\n",
    "            return tag[4]\n",
    "        elif tag[0] == 'P':\n",
    "            return tag[5]\n",
    "        elif tag[0] == 'M':\n",
    "            return tag[-1]\n",
    "        elif tag[0] == 'A':\n",
    "            return tag[5]\n",
    "\n",
    "    def get_config(self, tags, tokens, pmi_preps):\n",
    "        config = []\n",
    "        case = ''\n",
    "        for (tag, token) in zip(tags, tokens):\n",
    "            if tag == '' or tag[0] in 'RAI' or tag[0] == 'V' and tag[2] in 'mpg':\n",
    "                continue\n",
    "            elif tag[0] in 'S' and token not in pmi_preps:\n",
    "                case = self.get_case(tag)\n",
    "            elif tag[0] == 'S' and token in pmi_preps:\n",
    "                config.append(token)\n",
    "            elif tag[0] == 'C':\n",
    "                config.append(tag[0])\n",
    "            elif tag[0] in 'V':\n",
    "                config.append(tag[0])\n",
    "                case = ''\n",
    "            elif tag[0] in 'NPM':\n",
    "                if tag[0] in 'NP' and self.get_case(tag) == case:\n",
    "                    continue\n",
    "                if len(config) != 0 and config[-1][0] == 'P' and tag[0] == 'N' and config[-1][1] == self.get_case(tag):\n",
    "                    config[-1] = 'N' + self.get_case(tag)\n",
    "                if len(config) != 0 and config[-1][0] == 'M' and tag[0] == 'N' and self.get_case(tag) in 'ga':\n",
    "                    config[-1] = 'N' + self.get_case(tag)\n",
    "                elif (len(config) == 0 or config[-1] != (tag[0] + self.get_case(tag))):\n",
    "                    config.append(tag[0] + self.get_case(tag))\n",
    "                case = ''\n",
    "        \n",
    "        result = []\n",
    "        conj = False\n",
    "        is_verb = False\n",
    "        for i in range(0, len(config)):\n",
    "            if config[i][0] == 'M':\n",
    "                continue\n",
    "            if conj and is_verb and config[i] == 'V':\n",
    "                break\n",
    "            if config[i] == 'C':\n",
    "                conj = True\n",
    "                continue\n",
    "            if config[i] == 'V':\n",
    "                is_verb = True\n",
    "            if not ((config[i - 1][0] == 'M' or config[i - 1][0] == 'S')  and config[i] == 'Ng') or i == 0:\n",
    "                if config[i][0] in 'PN':\n",
    "                    config[i] = 'S' + config[i][1]\n",
    "                if config[i] != 'Sn':\n",
    "                    result.append(config[i])\n",
    "\n",
    "        for tag in tags[::-1]:\n",
    "            if tag and tag in ['что', 'как','чтобы','когда']:\n",
    "                result.append(tag)\n",
    "            elif tag and tag not in ['что', 'как','чтобы', 'когда']:\n",
    "                break\n",
    "\n",
    "    #         if config[i] == 'C' and config[i-1][1] == config[i+1][1]:\n",
    "    #             result.remove(config[i])\n",
    "    #             result.remove(config[i+1])\n",
    "        return ['Sn'] + result\n",
    "    \n",
    "    def extractor(self, verb, table):\n",
    "        \n",
    "        import csv\n",
    "        from time import time\n",
    "        start = time()\n",
    "\n",
    "        configs = []\n",
    "\n",
    "        global examples\n",
    "        \n",
    "        sentence_id = 0\n",
    "        for index, _ in table[table.lemma == self.verb].iterrows():\n",
    "            if table['gramm'].loc[index][2] not in 'mpgn':\n",
    "                tags  = [''] * 11\n",
    "                tokens = [''] * 11\n",
    "                tags[5] = table['gramm'].loc[index]\n",
    "                tokens[5] = table['token'].loc[index]\n",
    "                words = 0\n",
    "                left = 1\n",
    "                change_gen = False\n",
    "                skip_sentence = False\n",
    "                if table['lemma'].loc[index - 1] == 'не' and index >= 1:\n",
    "                    left += 1\n",
    "                    change_gen = True\n",
    "                while table['link'].loc[index - left] != 'PUNC' and words < 5 and index - left >= 0:\n",
    "                    words += 1\n",
    "                    tags[5 - words] = table['gramm'].loc[index-left]\n",
    "                    tokens[5 - words] = table['token'].loc[index-left]\n",
    "\n",
    "                    left += 1\n",
    "\n",
    "                right = 1\n",
    "                words = 0\n",
    "                while table['link'].loc[index + right] != 'PUNC' and words < 5 and index + right < len(table):\n",
    "                    words += 1\n",
    "                    tags[5 + words] = table['gramm'].loc[index + right]\n",
    "                    tokens[5 + words] = table['token'].loc[index + right]\n",
    "                    if tags[5 + words][0] == 'N' and self.get_case(tags[5 + words]) == 'g' and change_gen:\n",
    "                        change_gen = False\n",
    "                        tags[5 + words] = tags[5 + words][:4] + 'a' + tags[5 + words][5:]\n",
    "                    right +=1\n",
    "\n",
    "                if table['gramm'].loc[index + right] == ',' and words < 5 and table['gramm'].loc[index + right + 1] in ['что', 'как','чтобы', 'когда']:\n",
    "                    tags[6 + words] = table['lemma'].loc[index + right + 1]\n",
    "                    tokens[6 + words] = table['token'].loc[index + right + 1]\n",
    "\n",
    "                current_config = self.get_config(tags, tokens, self.possible_preps)\n",
    "                configs.append(current_config)\n",
    "                config_str = self.sort_args(' '.join(current_config))\n",
    "                if (config_str not in self.examples or len(self.examples[config_str]) < 5) and sentence_id != table.sent_id.loc[index]:\n",
    "                    self.examples[config_str] = self.examples.get(config_str, []) + [table.sent_id.loc[index]]\n",
    "                    sentence_id = table.sent_id.loc[index]\n",
    "\n",
    "        print('Sorry for making you wait for {}'.format(round((time() - start) / 60, 2)), 'minutes')\n",
    "        return configs\n",
    "    \n",
    "   \n",
    "    \n",
    "    def get_sent(self, table, sent_num):\n",
    "        \n",
    "        result = ' '.join(table[table.sent_id == sent_num].token)\n",
    "        result = result.replace('\\t', '\\\"')\n",
    "        for punc in ['.', ',', '!', '?', ':', ';',')']:\n",
    "            result = result.replace(' ' + punc, punc)\n",
    "        return result\n",
    "    \n",
    "    def sort_args(self, config):\n",
    "        config = config.split()[1:]\n",
    "        if len(config) >= 4:\n",
    "            return 'Sn ' + ' '.join(config)\n",
    "        config.remove('V')\n",
    "        new_config = []\n",
    "        for i in range(len(config)):\n",
    "            if config[i] in self.possible_preps:\n",
    "                continue\n",
    "            elif i > 0 and config[i - 1] in self.possible_preps:\n",
    "                new_config.append(config[i - 1] + ' ' + config[i])\n",
    "            else:\n",
    "                new_config.append(config[i])\n",
    "            \n",
    "        return ('Sn V ' + ' '.join(sorted(new_config))).strip()\n",
    "        \n",
    "    def government(self):\n",
    "        import pandas as pd\n",
    "        \n",
    "#         frames = []\n",
    "#         for i in range(1, 5):\n",
    "#             frames.append(pd.read_csv('.\\corpora\\corpus-i-part' + str(i) + '.txt', delimiter='\\t', header = 0))\n",
    "#         table = pd.concat(frames)\n",
    "        table = pd.read_csv('.\\corpora\\corpus-i-part1.txt',delimiter='\\t',header=0)\n",
    "        configs = self.extractor(self.verb, table)\n",
    "        \n",
    "        import random, statistics\n",
    "        config_freq = {}\n",
    "\n",
    "        for i in configs:\n",
    "            config_str = self.sort_args(' '.join(i))\n",
    "            config_freq[config_str] = config_freq.get(config_str, 0) + 1\n",
    "\n",
    "        med = statistics.median(config_freq.values())\n",
    "        average = statistics.mean([i for i in config_freq.values() if i > med])\n",
    "        \n",
    "        final_result = []\n",
    "        \n",
    "        for chain in sorted(config_freq, key=config_freq.get, reverse=True):\n",
    "            final_result.append((chain, config_freq[chain], self.get_sent(table, random.choice(self.examples[chain]))))\n",
    "            if config_freq[chain] < average:\n",
    "                break\n",
    "        return final_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "document = pd.read_csv('.\\corpora\\corpus-i-part1.txt', delimiter='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "najti = VerbGovernment('найти', document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idti = VerbGovernment('идти', document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vesti = VerbGovernment('вести', document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry for making you wait for 0.17 minutes\n"
     ]
    }
   ],
   "source": [
    "answer = najti.government()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sn V Sa 183 \n",
      " – Кто будет собираться в клубе, если крыша течет, тазики кругом стоят, пожарная сигнализация замыкает? \" В Москве нашли фирму, заплатили деньги, они нам ставят... \" Что это такое? \n",
      "\n",
      "\n",
      " Sn V 97 \n",
      " Деньги, те, что нашла в шкафу, в кармане маминой шубы, закончились. \n",
      "\n",
      "\n",
      " Sn V Sg 69 \n",
      " Эта она нашла эксперта, и в результате \" Волга \", балансовая стоимость которой превышала 30 тысяч рублей, продана через комиссионный магазин всего за 19, 2 тысячи. \n",
      "\n",
      "\n",
      " Sn V S- 43 \n",
      " Ее нашли художники-постановщики. \n",
      "\n",
      "\n",
      " Sn V Sa в Sl 29 \n",
      " Нашли сумку в тумбочке, и сразу без разговоров – наряд. \n",
      "\n",
      "\n",
      " Sn V в Sl 27 \n",
      " По мнению аналитика ИК \" Финам \" Владислава Кочеткова, инициатива властей Иркутской области, возможно, найдет понимание в Министерстве сельского хозяйства. \n",
      "\n",
      "\n",
      " Sn V S- Sa 25 \n",
      " То есть он вроде бы неплохо поворачивает, при развороте вписывается в три стандартные полосы, но любая попытка припарковаться вдоль дороги равна подвигу, так как даже если вы найдете подходящую дыру рядом с бордюром ( в которую влезет автовоз со \" смартами \"), оглянувшись назад, вы увидите... А ничего вы не увидите, кроме пробивающихся сквозь стекла кунга солнечных лучей. \n",
      "\n",
      "\n",
      " Sn V Sa Sg 19 \n",
      " \" Но даже эта сумма не может быть быстро получена, поскольку имущество носит специфический характер и не сразу найдет покупателей, – отметил Богданов. \n",
      "\n",
      "\n",
      " Sn V Sa Sd 15 \n",
      " Соответствие празднику * Отправляя фотографии или видео, вы предоставляете VladNews право на их использование; В том случае если по запросу пользователя \" Яндекс \" найдет не один профиль, максимально заполненный из них будет показан в результатах поиска, остальные — на отдельной странице. \n",
      "\n",
      "\n",
      " Sn V S- Sg 14 \n",
      " Денег так и нашли, и все вернулось на круги своя. \n",
      "\n",
      "\n",
      " Sn в Sl V Sa 11 \n",
      " В последний день пребывания на вулкане Исаев с сыном в этом районе нашли очень холодное озерцо с необычно гладким дном, при ударе о дно из-под воды выходили газы. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in answer:\n",
    "    print('\\n', row[0], row[1], '\\n', row[2], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['для', 'в', 'у', 'из', 'на']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "najti.possible_preps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation time: 6.24015196164449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['брейк', 'родословная', 'захватчик', 'переговоры', 'телепередача']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vesti.pmi_nouns()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
